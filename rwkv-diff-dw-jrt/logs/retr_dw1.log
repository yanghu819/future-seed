0.55898 M parameters
step 0: train loss 3.1355, val loss 3.1355, time 0.59 seconds
retr acc 0.0988
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=2682;b=0349;c=020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.1927, val loss 2.1947, time 22.03 seconds
retr acc 0.2100
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=2604;b=4558;c=888221281215511111111155161661665116111116115151111565151116116616111561115651611666651611161166615111161116566165511666111151551515611166166151516651561565116661555551561516666656565511511115661665615511166551511615115661116651116116611561

step 100: train loss 1.9528, val loss 1.9498, time 42.52 seconds
retr acc 0.2650
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=7562;b=2722;c=222222122222221222221222212112222222222222222222222222882288112822222222228122222221228222222221822122122112122121202102200001222222121211002201000112210021110002011101211022022112011121102011211211022101001111101101101111210011012011111110

step 150: train loss 1.8917, val loss 1.8813, time 63.06 seconds
retr acc 0.2925
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=9561;b=7478;c=969967777876886766767766876876868666666678687886668888886867887888886766688666668888686666868688669668866686688666666666666868668668666866666666666866668666666866366666888686686686666866666666666666666666666668686666668666666666666666666666

step 199: train loss 1.8294, val loss 1.8901, time 83.54 seconds
retr acc 0.2863
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=5293;b=4394;c=454443444444454434444445445445444444444444444444444444440444454444444444444444444444444444444445444454444444444944444444444444444444444444455494444444494994444449444444444944444444444449444544445444444444544444494944444444444544494444449494

Total training time: 90.67 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
a=4000;b=0929;c=4
