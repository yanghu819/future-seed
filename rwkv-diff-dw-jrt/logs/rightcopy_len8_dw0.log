0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.46 seconds
rightcopy acc 0.0975
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=67106993|M=886020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.3088, val loss 2.3123, time 21.90 seconds
rightcopy acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=67834520|M=886304344334343340303340334004034340040440444344034434043440404343400334443404344340034443443430403033434440433040034344333004044400034344040443440300404404033300340340444304300034043330033330303334444440030044404344340334440434004404340003340

step 99: train loss 2.3041, val loss 2.3063, time 44.52 seconds
rightcopy acc 0.0875
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=71877894|M=889565566566466655646664664645446565466564565664446564464465455545445544556665455665554646656556644564444646654656466546544455644544444555445554645555664465546665445444544564545565665565464655644454546644456645456556546656555645664655455564455

Total training time: 52.31 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=70873761|M=8076
