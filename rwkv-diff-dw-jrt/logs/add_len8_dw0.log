0.556684 M parameters
step 0: train loss 2.6391, val loss 2.6391, time 0.38 seconds
add acc 0.1087
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
67106993+8864076020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.3072, val loss 2.3150, time 21.79 seconds
add acc 0.0988
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
67834520+8866756759557579575957559555579975975997579755755755757777575757975779957995577757559579579575777559995779575977979557775577975997795995975799999755775557995779575757797759999599779955597975795999759797959555777597559797979995557579957997777577979

step 99: train loss 2.3055, val loss 2.3084, time 43.43 seconds
add acc 0.1100
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
71877894+8892282307733037700777777770737300730700773770303777033300737003003330370373737307307337003337007373730377777007737373300770733370303033030037070373000000033033770707073733077733703033003373007373373370770300303000703000300337703000733733030777777

Total training time: 51.12 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
70873761+80767553
