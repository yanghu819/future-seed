0.557964 M parameters
step 0: train loss 2.9444, val loss 2.9444, time 0.37 seconds
rule acc 0.1031
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=36920327|M=723020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 1.6987, val loss 1.7257, time 21.79 seconds
rule acc 0.3306
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=90314146|M=903404944443040494940444044000094494994444449494990449404994449090040004949944444444449444444444049444444444444444444440449444494444444444444444444444644444444464444456444444444444444444444444444444444444445444444444444444444444444446444444444

step 99: train loss 1.4401, val loss 1.4452, time 43.44 seconds
rule acc 0.3787
Total steps: 104 for 240 tokens
Avg decoded per step: 2.31
Sample:
A=62398071|M=623222222226666166666366666666316366636333663633333336333363333333333333333333633333333333333353333353533353333353335333333333333333353333333333333335333533353333333333353335333353335353333553333353333333353333333337533333333333353333335333333

Total training time: 48.60 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=20621391|M=1939
