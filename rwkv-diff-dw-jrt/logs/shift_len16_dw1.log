0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.48 seconds
shift acc 0.0978
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=34151452968666020011000212112121212021211001001222002200222211212200200001010120200121001202111020220112112210022002122000200020221010220211010011221200212001200021220221101212121022022212221100110011201021122122000220100210211220012101110211221211122210

step 50: train loss 2.3117, val loss 2.3118, time 30.72 seconds
shift acc 0.0988
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=09729150103877288929292922988889922922299988289822988889829229998999298982988989829922829292289282929298998898982928299982288929892299898222988988282899222288898998299288299929829829289299828299988298829928822982828989988999292889292999292928222228898998

step 99: train loss 2.3079, val loss 2.3062, time 61.11 seconds
shift acc 0.0950
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=86325625432957434433433844838444433334888338384438444833443343338844883348448884334348438833343434333333343338383388334448483344433848843433884338344348438344843448888333888333888344338848338384448334848448388883344444348344433333848834483444838883833844

Total training time: 71.82 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=072856470891433
