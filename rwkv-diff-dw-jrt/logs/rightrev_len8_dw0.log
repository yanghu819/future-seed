0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.38 seconds
rightrev acc 0.0975
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=67106993|M=767020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.3083, val loss 2.3120, time 22.26 seconds
rightrev acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=67834520|M=765044333343303433044303434403444444443000334004004000030444334400343430440033303434000404003444403000344343334043044033304300003330440330343034330430040004434340440400340044034303343443333444304400000044400400044034340403344400340444034043443

step 99: train loss 2.3041, val loss 2.3062, time 43.87 seconds
rightrev acc 0.0875
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=71877894|M=528665565664454464464664654566465566646565666664454564456545645656555446666646466645646464656665566564455466444456464555456655554655656464644556654555664465546665445446645566455555665466654655466446465544655546646545445546644554466565456555664

Total training time: 51.59 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=70873761|M=0556
