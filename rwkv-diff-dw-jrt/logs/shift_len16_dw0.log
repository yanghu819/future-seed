0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.46 seconds
shift acc 0.0978
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=34151452968666020011000212112121212021211001001222002200222211212200200001010120200121001202111020220112112210022002122000200020221010220211010011221200212001200021220221101212121022022212221100110011201021122122000220100210211220012101110211221211122210

step 50: train loss 2.3110, val loss 2.3116, time 29.70 seconds
shift acc 0.0988
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=09729150103877229929899289889829288889989299982989982829892298229289888929999999298282292999298929289289989999288928992999228889289898282888289828828998282299822822982828898898229828299299922898989888992929882988999929989898892929982822292889829289882998

step 99: train loss 2.3082, val loss 2.3066, time 60.22 seconds
shift acc 0.0950
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=86325625432957838833833433388343334334348443838433834838334443833338448384488838444383888433388388434483348884844838888484434444434444438833388338838448334884333434883844834443838448344333388883384483484883884883888383438483844884384843484384888348834438

Total training time: 70.42 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=072856470891433
