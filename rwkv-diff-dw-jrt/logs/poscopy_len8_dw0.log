0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.46 seconds
poscopy acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=33176819|M=333020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.2166, val loss 2.1808, time 21.52 seconds
poscopy acc 0.2100
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=69174293|M=333911199171117111718117871881711111118117711111111111871177171111871187711118718111118171111181777818181117717118787111181711111778117187177118111817811888771817187187718711117181781111187181711117887811118187178871818871181178117181711118118

step 99: train loss 2.0689, val loss 1.9897, time 42.85 seconds
poscopy acc 0.2233
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=22751723|M=555775557757477774474740747707707007077707777074704000707777740047747440474774004070007770047777477707407047070770740077400077700477040747744447777007077400770440707770744477777407077000477744074407400474004477747777747770074474770444747007477

Total training time: 50.49 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=27946115|M=7777
