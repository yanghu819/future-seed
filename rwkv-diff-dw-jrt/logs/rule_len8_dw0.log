0.557964 M parameters
step 0: train loss 2.9444, val loss 2.9444, time 0.38 seconds
rule acc 0.1031
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=36920327|M=723020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 1.6457, val loss 1.6579, time 21.76 seconds
rule acc 0.3563
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=90314146|M=903699999999499949949999999999999419999999299999499999929999929999929994299994949499999999999924999994999999999999999999999949999929999292999929999992999992922898998998929899929899298999929929999999929999999289929999989999999999899999929999992

step 99: train loss 1.3930, val loss 1.3756, time 43.19 seconds
rule acc 0.3912
Total steps: 107 for 240 tokens
Avg decoded per step: 2.24
Sample:
A=62398071|M=623222222226666666666666666666666666676666666766666766666666666666666666666666666667666666676666666666666666666666666666666666666666666666666666666676666667667666667676666667666666666666666666666666666666666666666666666666666666666666666366663

Total training time: 48.47 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=20621391|M=1939
