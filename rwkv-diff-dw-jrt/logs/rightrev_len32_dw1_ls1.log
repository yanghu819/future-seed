0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.58 seconds
rightrev acc 0.1055
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=75362403773101020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.2762, val loss 2.2720, time 38.49 seconds
rightrev acc 0.1528
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=45680825809814880883038808088838008030880300888000083800000378807080087777870070070708003878003878880030003303730878800880883888870708080038338338780873088373803873708880000008038888887030803308880830033833008000300300008003033030330088300838833080880008

step 99: train loss 2.0905, val loss 2.0775, time 77.17 seconds
rightrev acc 0.2286
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=04769740283726777777777737776776770777777070737777777777777777777777077777377777770777777777777777377777777307777777777777777777777777777777777777777337777777777737077377770773777773377777777377737377777777777773777777770303777777777777700777777777707777

Total training time: 89.87 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=577285349434525
