0.558214 M parameters
step 0: train loss 2.9957, val loss 2.9957, time 0.73 seconds
struct acc 0.0950, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":58955505,"b020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 1.9802, val loss 1.9607, time 23.35 seconds
struct acc 0.2931, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":34227618,"b366661666661216166666666616666666666166661666666661666666866181826186666686161668116661666666666666866666166666166668666661866866666686616166166666181668516666611666666616686686668668666686616666688666866116668166666666666668851666618666666

step 100: train loss 1.1796, val loss 1.1976, time 45.30 seconds
struct acc 0.5012, exact 0.0000
Total steps: 130 for 240 tokens
Avg decoded per step: 1.85
Sample:
{"a":33665710,"b333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333335333333333333333333333333333333333333333333333333333333333333333330333353333333333333333333333333333333333333333333333333333333333333332333333

step 150: train loss 0.9444, val loss 0.9449, time 64.74 seconds
struct acc 0.5991, exact 0.0000
Total steps: 23 for 240 tokens
Avg decoded per step: 10.43
Sample:
{"a":06424121,"b226242202222222222262222222262222222222222622222222222222222222222222222222226262222262222222222222222228222222222222222222222222222222222222222222222226282222222226222622222222222222222222222222222222222222222222222222222222222222222222222

step 199: train loss 0.5960, val loss 0.5953, time 83.48 seconds
struct acc 0.7172, exact 0.0050
Total steps: 31 for 240 tokens
Avg decoded per step: 7.74
Sample:
{"a":37612729,"b372772227222922777277222222222277272227727222722222222222272227222722722222222222222222222277222222222222222222227222222222222222222222222222222222222222222222222222222222222222222222222222222622222222222222222222222222222222222222222222222

Total training time: 87.48 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
{"a":96472722,"b9
