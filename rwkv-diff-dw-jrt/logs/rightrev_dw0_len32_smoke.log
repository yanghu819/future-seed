0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 1.06 seconds
rightrev acc 0.1070
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=24594899000970020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.3068, val loss 2.3088, time 40.23 seconds
rightrev acc 0.1022
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=68111692300154333893899388899999889939993838938389993339983888339998389838893393993839999989998888933989938998898338393839839939333383899333389898999898388893983889839893899389989999389338938339999839398893833989888998339899899338393889838988398833883338

step 100: train loss 2.3080, val loss 2.3080, time 80.83 seconds
rightrev acc 0.0952
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=83022838492748086888066668868008000660886806086686688666880080060066866066068866600068660806608888666808686868000868080066686060080666860086668088666080886080868060666886068068660006068860660000660680008666066686680680800666606686686068668886600000866006

step 150: train loss 2.3045, val loss 2.3036, time 122.61 seconds
rightrev acc 0.0916
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=52653856839824888636366886338883366386886383366636883368663888638683383386338366333638386338368363336838383633368336633333666683386683683368636688888863366368383838388368363683888383333833668863833866388383336338866366383336636883666868386836866386368363

step 199: train loss 2.3022, val loss 2.3034, time 163.80 seconds
rightrev acc 0.0991
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=61972216292965666846848484464664886646686884886866866844888848868868644688466864448888464864648886448886888884888446886846644846888846668884484844848664666846688646884486444448446684884848466848884664468664844646686644464688444684664488686868668648844886

Total training time: 176.73 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=303113651236558
