0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 1.15 seconds
rightcopy acc 0.1070
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=24594899000970020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.2989, val loss 2.3008, time 42.41 seconds
rightcopy acc 0.1322
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=68111692300154339992939222922222393332332292992293329323292329999923393923339933933399293222332233339332932923232923999333229292997779297272997927272772777979277977997992727299779227779277929797222299722277977997727992323999232993323229237997792929772797

step 100: train loss 2.2093, val loss 2.2124, time 82.43 seconds
rightcopy acc 0.1895
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=83022838492748330636338633632688663386668863266338633686686383338686668633632336683638386386366638336386326636636833636638688388686333366663632316363326683283232633086332323231831832830326832631318683131883063031632303286081860663181686636666833636668636

step 150: train loss 1.9889, val loss 1.9880, time 122.81 seconds
rightcopy acc 0.2594
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=52653856839824869786888687667776677666876647664676477687764664776464676487764606076067676767616061760780667615676647777761661747676767669766877476864647677647878766878787677806868768769777968787770685657767678767078788877687776788776776576767273728176727

step 199: train loss 1.9302, val loss 1.9206, time 163.85 seconds
rightcopy acc 0.2680
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=61972216292965609989719799285624239396942622879767927907827949771719827762798997827279672977927292727982978987798797678782778717070515077805174815472737654768252605257352845525750577650555855552553574517559761545650515666647666250762536451707762776226575

Total training time: 176.65 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=303113651236553
