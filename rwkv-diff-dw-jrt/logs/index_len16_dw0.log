0.557708 M parameters
step 0: train loss 2.8904, val loss 2.8904, time 0.38 seconds
index acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=42788538813264020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.1911, val loss 2.2377, time 21.76 seconds
index acc 0.1950
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=02197801974211299922922988999992299222992989998982298888999928299892822828888888892292829298989982889228882988988982892288888882989998292988999999829889898298989898882992989899928992899829298889982929892222998928929829282289288929222988282922989282999989

step 99: train loss 2.0779, val loss 2.0876, time 43.18 seconds
index acc 0.2425
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=84985113484430449444844444414449499441444449141144491149441414149141149194444444994191444991144949144114499944194411994449491491994494994449444491944999444994191444441444441499419494411499994114944919999149999999949194449114149991944999191444941499449191

Total training time: 50.76 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=879938197177317
