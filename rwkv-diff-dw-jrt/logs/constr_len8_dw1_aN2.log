0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.37 seconds
constr acc 0.1231
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
P=39689277|M=791020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 1.1463, val loss 1.1378, time 21.85 seconds
constr acc 0.6475
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
P=61087963|M=378667767677767067770667676776776567767777567666667777766666767775777777777555995899958989959889598567666667555555555555956956555559559599598555555555555555555556575597788859555955957559559965557565565659565555595655555555955585595555555555595

step 99: train loss 0.3730, val loss 0.3585, time 44.26 seconds
constr acc 0.7906
Total steps: 71 for 240 tokens
Avg decoded per step: 3.38
Sample:
P=76611917|M=777777777777777777777776667777677767676777657776677987793666666666666669999299999999999999999999999266666666666666666666666666666666666666666676666666666666666666665555555555555555555555515555555555555555666666565667666666666667666666666576666

Total training time: 48.88 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
P=96944054|M=4254
