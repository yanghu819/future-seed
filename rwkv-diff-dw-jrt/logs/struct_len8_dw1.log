0.55822 M parameters
step 0: train loss 2.9957, val loss 2.9957, time 0.38 seconds
struct acc 0.0969, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":67106993,"b020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 1.8909, val loss 1.8369, time 21.88 seconds
struct acc 0.3272, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":67834520,"b365365752555255556552652566252252555662655256665556655556255666655526665662666556666656655556226655565256656565265666565252562226552655552555562562656262626225662552556666666662565526656255566556265255255255256555526225666265656555555555556

step 99: train loss 1.1090, val loss 1.1326, time 43.49 seconds
struct acc 0.5397, exact 0.0000
Total steps: 72 for 240 tokens
Avg decoded per step: 3.33
Sample:
{"a":71877894,"b477777777777779777777777777777777777777777777777777773777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777787777777777777777777777777777777777777777777777777777777773787777777777777777777777777777777777

Total training time: 48.16 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
{"a":70873761,"b7
