0.556684 M parameters
step 0: train loss 2.6391, val loss 2.6391, time 0.37 seconds
add acc 0.1087
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
67106993+8864076020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.3087, val loss 2.3178, time 21.72 seconds
add acc 0.0813
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
67834520+8866756579777797757977599757979957999999959997995559559555575599779955797975995577757979555959557999957555799797779597599577759755557775555775779579775975595559979795995955795599579757797997777775779955555599955955799579795959999955795999579557997

step 99: train loss 2.3040, val loss 2.3075, time 43.28 seconds
add acc 0.0912
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
71877894+8892282007470770070044747477044707700440070777000000044744770774774447407404040470470440774447704440740077000770040404477007044407474744747740707404700444474744007070704044700044074744774404770404404070704074040704400447007440444074007044744407777

Total training time: 50.82 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
70873761+80767550
