0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.38 seconds
poscopy acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=33176819|M=333020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.1897, val loss 2.1833, time 21.76 seconds
poscopy acc 0.1950
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=69174293|M=333899881899911981189191198189819918189981118814018181111114884488141818481414144411481181188418811448118188114818114411814881181848418118441418184411118141114144141884484111841144181141441401114111101108118111814141414441181114141410811184141

step 99: train loss 2.0803, val loss 1.9896, time 43.22 seconds
poscopy acc 0.2333
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=22751723|M=555558533535333355353355353835535538858833833555555538353853353835355535833853558855355558355555855588855838553355353383355585335583535858335538558833338558855833858833885383533388333885855888588583588555338858383388385853833558333558538585335

Total training time: 50.84 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=27946115|M=7777
