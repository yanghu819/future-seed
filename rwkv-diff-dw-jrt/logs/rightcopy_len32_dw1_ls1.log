0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.58 seconds
rightcopy acc 0.1055
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=75362403773101020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.3005, val loss 2.2987, time 38.87 seconds
rightcopy acc 0.1252
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=45680825809814900888808898088900898080098000000008999880990990008889998900990090809988888890009099808000000898980898800909090898899800000098899889808800899800858800908988808508990800058080898990900008898808008800800098058508009590050588088800000888809980

step 99: train loss 2.1791, val loss 2.1746, time 77.34 seconds
rightcopy acc 0.2166
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=04769740283726838833834884848844878847744844444777844874788484784887848444848744878477884847888888844744488884878874874877844437744443777437434477344474447334447433377433477774347443443733443433334747733443333337747333343443473474743374444433374347374343

Total training time: 90.03 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=577285349434523
