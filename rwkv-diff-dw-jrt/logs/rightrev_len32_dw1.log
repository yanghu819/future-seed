0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.58 seconds
rightrev acc 0.1055
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=75362403773101020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.2716, val loss 2.2681, time 38.78 seconds
rightrev acc 0.1505
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=45680825809814038338080338083300888338388030333300338030333888003380338083083338080033008803303003880333880880080308800383038303300330003008088333388330880080008333080883000800888030083003838888880088833883883300038030308380080833300088883800083038380330

step 99: train loss 2.0888, val loss 2.0739, time 77.51 seconds
rightrev acc 0.2291
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=04769740283726404040004000004044000040040940094000000000000000000000043000000003000000030300000300000000300000309030000093000000000030300030009000000000003000000900000009990000000000033000000090093030300000000000000000000009000000000900000000000000000000

Total training time: 90.09 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=577285349434524
