0.55898 M parameters
step 0: train loss 3.1355, val loss 3.1355, time 0.58 seconds
retr acc 0.0988
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=2682;b=0349;c=020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.1042, val loss 2.0994, time 20.88 seconds
retr acc 0.2500
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=2604;b=4558;c=222555525582555555282525582555555552858225885885552852888288852282885558582222828585588582888855588528888248288882828488848484484878878478884788844788787787878874747774848488474778448877777477748744488874778777774888888474488748787778748877

step 100: train loss 1.9257, val loss 1.9326, time 41.98 seconds
retr acc 0.2762
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=7562;b=2722;c=227222822222228222227222272772228222222222222722222222882227282272722222222222272272722222222822822282822822872828272872277772282222727277882287888887882278882772788878288722722882788827872788788788777828278878878778878888377788783788888887

step 150: train loss 1.8755, val loss 1.8612, time 64.54 seconds
retr acc 0.2938
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=9561;b=7478;c=946648669686846466666466469694666666669466466466664666646668866664666866664666666446646666464664662666466646646666666666666464664664666666666666666466664666666466866666444646646646666466666666666666666666666664646666664666666666666666666666

step 199: train loss 1.8310, val loss 1.8801, time 85.17 seconds
retr acc 0.2863
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
a=5293;b=4394;c=434449444444434444444443449449444444444499444444449444444444444444444444449444449444444424444444244944944944444444444444444444442444449444444444444494444444444442444444444444444244494442494444244444444444444244444444444444444444444949444424

Total training time: 92.04 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
a=4000;b=0929;c=4
