0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 0.58 seconds
rightrev acc 0.1055
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=75362403773101020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.3080, val loss 2.3098, time 38.82 seconds
rightrev acc 0.0978
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=45680825809814955777757797577955797575597555555557999775995995557779999955997595759977777795559997777599557779977995779599999797799779997997975997977559995759579759759795777597777795557975795595999955799977577557797559999999597977755995957799777795557959

step 99: train loss 2.3036, val loss 2.3028, time 77.32 seconds
rightrev acc 0.0969
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=04769740283726323322322622233262226226263662323622326323226662322223663236633323666232333622232622236222662666633266333236332636632666626263662233636226632262666332226333266662636323233223366336233263333266666636626262266632623362636336636666322632322636

Total training time: 89.86 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=577285349434522
