0.557708 M parameters
step 0: train loss 2.8904, val loss 2.8904, time 0.38 seconds
index acc 0.0900
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=42788538813264020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.2304, val loss 2.2472, time 21.78 seconds
index acc 0.1750
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=02197801974211878873388377878873878887881778878788787338873878838838788337378887817118118818878881838788888788778188887118778718887181228828221281828282818281888812212128288211188288812818211188211882818821221122818822818221288812828211888182212881182818

step 99: train loss 2.0658, val loss 2.0862, time 43.47 seconds
index acc 0.2387
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
A=84985113484430441334413343343413143344434344444334434443413444444444133434443431443144444441314313434314444434343114344344334144343434444444113344433331434441141431314344341441344443444331441333314343444413434343131444334341344334434444444314134434333341

Total training time: 51.01 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
A=879938197177317
