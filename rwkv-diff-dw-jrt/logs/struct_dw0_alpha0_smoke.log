0.558214 M parameters
step 0: train loss 2.9957, val loss 2.9957, time 0.78 seconds
struct acc 0.0950, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":58955505,"b020011000212112121212021211001001222002200222211100222010100112020001020112012012020200021211022110211220202121202012012220121021200002002000201220010222120000012220012120211200111100120110210000211012212111012110102112102011100121200202201

step 50: train loss 2.0275, val loss 2.0365, time 21.66 seconds
struct acc 0.2675, exact 0.0000
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
{"a":34227618,"b742341248888884484248488844444244448448824888488114888418444144814488484148884844111841444444144448444418444144484448144414814148444814844141188844848844111848414141148848188448448144448844441884818444844144144484811441141418481184144411414

step 100: train loss 1.5583, val loss 1.5701, time 42.92 seconds
struct acc 0.3991, exact 0.0000
Total steps: 94 for 240 tokens
Avg decoded per step: 2.55
Sample:
{"a":33665710,"b336060600360000004004040000000000000000000000000000000000000000000004000000000000000000600000000000000000000000000000000000400000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000000000000000000

step 150: train loss 1.3390, val loss 1.3397, time 62.34 seconds
struct acc 0.4684, exact 0.0000
Total steps: 220 for 240 tokens
Avg decoded per step: 1.09
Sample:
{"a":06424121,"b044412142441124406447946797000079773855555555358993798697708369378720892404464826644410010182845794554654664966555577574463949558784882888888888988888988898868868866862896866996282846284896842698928998948602999999007752037364077324077307760

step 199: train loss 1.1781, val loss 1.1782, time 83.49 seconds
struct acc 0.5484, exact 0.0000
Total steps: 194 for 240 tokens
Avg decoded per step: 1.24
Sample:
{"a":37612729,"b672772967776977776677667698766999996997966777777997779877997777977977977977794949999944795343658319998299898877898238133822835552223913893385381292232232222222222222222222222222222222222222222222222222222222222222222222222222222222222999422

Total training time: 90.87 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
{"a":96472722,"b4
