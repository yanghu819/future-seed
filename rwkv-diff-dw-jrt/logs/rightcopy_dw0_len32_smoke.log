0.557452 M parameters
step 0: train loss 2.8332, val loss 2.8332, time 1.19 seconds
rightcopy acc 0.1070
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=24594899000970020011000212112121212021211001001222002200222211212200200001010120200121001202111101212210212020100001001102212110022022100010022101020000122101011222222020100110111202020200102102211012202020222100220002222211210101221110120021110200121102

step 50: train loss 2.3070, val loss 2.3090, time 41.77 seconds
rightcopy acc 0.1022
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=68111692300154839338839988893933398399388883999998839839899988339399389338899398839388939893989833838893898398383333998989898389988998889889893888883339383339993333939989888333998333883383398999998839393339999839883333339998383999993889399988999983339838

step 100: train loss 2.3093, val loss 2.3090, time 82.35 seconds
rightcopy acc 0.0952
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=83022838492748868866866066688606660660608006868066860868660006866668008680086868000686868066686066680666006000088600888680686080086000066608006688080660086606000886660888600006080868688668800880688608888600000086060606600086068806080880080000866086866080

step 150: train loss 2.3046, val loss 2.3035, time 123.81 seconds
rightcopy acc 0.0916
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=52653856839824883833863836838366366666866636888383666686666838366833866686838668868383838383886886886883633888663368883636338383683663886368868368866666638383686888666833333683336666838883666866666336338866666388338838638366333833666388888366683363833838

step 199: train loss 2.3021, val loss 2.3034, time 163.67 seconds
rightcopy acc 0.0991
Total steps: 240 for 240 tokens
Avg decoded per step: 1.00
Sample:
L=61972216292965444884486844664648468864888484484648864846648488666846846448686864844666666686866846486448446846448886646486886866884864848864848644446446844664488668868486468888668444446646484666688848688664664688868686686664448886648488884484446648866688

Total training time: 176.73 seconds
Total steps: 1 for 1 tokens
Avg decoded per step: 1.00

Output:
L=303113651236558
